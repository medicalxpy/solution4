{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/volume1/home/pxie/.local/lib/python3.9/site-packages/cupy/_environment.py:437: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  CuPy may not function correctly because multiple CuPy packages are installed\n",
      "  in your environment:\n",
      "\n",
      "    cupy-cuda101, cupy-cuda117\n",
      "\n",
      "  Follow these steps to resolve this issue:\n",
      "\n",
      "    1. For all packages listed above, run the following command to remove all\n",
      "       existing CuPy installations:\n",
      "\n",
      "         $ pip uninstall <package_name>\n",
      "\n",
      "      If you previously installed CuPy via conda, also run the following:\n",
      "\n",
      "         $ conda uninstall cupy\n",
      "\n",
      "    2. Install the appropriate CuPy package.\n",
      "       Refer to the Installation Guide for detailed instructions.\n",
      "\n",
      "         https://docs.cupy.dev/en/stable/install.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  warnings.warn(f'''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData中的基因数: 36263\n",
      "基因嵌入中的基因数: 33622\n",
      "共有基因数: 22654\n",
      "AnnData中的基因数: 21563\n",
      "基因嵌入中的基因数: 33622\n",
      "共有基因数: 20599\n",
      "Settings: \n",
      "                N Components: 50\n",
      "                Topic Prior Mean: 0.0\n",
      "                Topic Prior Variance: None\n",
      "                Model Type: prodLDA\n",
      "                Hidden Sizes: (100, 100)\n",
      "                Activation: softplus\n",
      "                Dropout: 0.2\n",
      "                Learn Priors: True\n",
      "                Learning Rate: 0.002\n",
      "                Momentum: 0.99\n",
      "                Reduce On Plateau: False\n",
      "                Save Dir: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 4599.380814302885 best_loss: 4599.380814302885\n",
      "epoch: 1 loss: 4521.498512620193 best_loss: 4521.498512620193\n",
      "epoch: 2 loss: 4506.651975661058 best_loss: 4506.651975661058\n",
      "epoch: 3 loss: 4495.341301081731 best_loss: 4495.341301081731\n",
      "epoch: 4 loss: 4481.653109975961 best_loss: 4481.653109975961\n",
      "epoch: 5 loss: 4467.681467848558 best_loss: 4467.681467848558\n",
      "epoch: 6 loss: 4457.145500300481 best_loss: 4457.145500300481\n",
      "epoch: 7 loss: 4450.3447265625 best_loss: 4450.3447265625\n",
      "epoch: 8 loss: 4445.6375375600965 best_loss: 4445.6375375600965\n",
      "epoch: 9 loss: 4441.073617788462 best_loss: 4441.073617788462\n",
      "epoch: 10 loss: 4436.869373497596 best_loss: 4436.869373497596\n",
      "epoch: 11 loss: 4433.271198918269 best_loss: 4433.271198918269\n",
      "epoch: 12 loss: 4429.919673978366 best_loss: 4429.919673978366\n",
      "epoch: 13 loss: 4426.835892427885 best_loss: 4426.835892427885\n"
     ]
    }
   ],
   "source": [
    "from model import CTM\n",
    "from dataset import CTMDataset\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import torch\n",
    "from fusion_CTM import get_cellemb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "from utils.cell_embedding import generate_cell_embedding\n",
    "\n",
    "\n",
    "adata_path1=\"/volume1/home/pxie/data/PBMC.h5ad\"\n",
    "adata_path2=\"/volume1/home/pxie/data/Cortex.h5ad\"\n",
    "gene_embedding_path=\"/volume1/home/pxie/data/embeddings/GenePT.pkl\"\n",
    "model_name=\"gpt_base\"\n",
    "cell_embeddings1, gene_counts_common1,_=generate_cell_embedding(\n",
    "    adata_path=adata_path1,\n",
    "    gene_embedding_path=gene_embedding_path)\n",
    "cell_embeddings2, gene_counts_common2,_=generate_cell_embedding(\n",
    "    adata_path=adata_path2,\n",
    "    gene_embedding_path=gene_embedding_path\n",
    ")\n",
    "num_genes1 = gene_counts_common1.n_vars\n",
    "num_genes2 = gene_counts_common2.n_vars\n",
    "# 生成示例词汇表逆映射\n",
    "id2token1 = {i: list(gene_counts_common1.var_names)[i] for i in range(num_genes1)}\n",
    "cell_embeddings_numpy1 = cell_embeddings1.detach().numpy()\n",
    "train_dataset1 = CTMDataset(X_contextual = cell_embeddings_numpy1,X_bow = gene_counts_common1.X.toarray(),idx2token=id2token1)\n",
    "id2token2 = {i: list(gene_counts_common2.var_names)[i] for i in range(num_genes2)}\n",
    "cell_embeddings_numpy2 = cell_embeddings2.detach().numpy()\n",
    "train_dataset2 = CTMDataset(X_contextual = cell_embeddings_numpy2,X_bow = gene_counts_common2.X.toarray(),idx2token=id2token2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "lr=2e-3\n",
    "num_epochs=100\n",
    "\n",
    "\n",
    "num_topics = 50\n",
    "ctm = CTM(contextual_size=cell_embeddings1.shape[1],\n",
    "            bow_size=num_genes1,\n",
    "            n_components=num_topics,\n",
    "            batch_size=1024,\n",
    "            device=device,\n",
    "            lr=lr,\n",
    "            num_epochs=num_epochs)\n",
    "prior_mean,prior_variance=ctm.fit(train_dataset1,patience=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
